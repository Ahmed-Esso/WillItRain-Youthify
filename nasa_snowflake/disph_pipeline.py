import io
import xarray as xr
import pandas as pd
import snowflake.connector
from dagster import job, op, DynamicOut, DynamicOutput
import earthaccess
from datetime import datetime, timedelta

# ==========================
# Snowflake Config
# ==========================
SNOWFLAKE_ACCOUNT = "KBZQPZO-WX06551"
SNOWFLAKE_USER = "A7MEDESSO"
SNOWFLAKE_PASSWORD = "Ahmedesso@2005"
SNOWFLAKE_AUTHENTICATOR = "snowflake"
SNOWFLAKE_ROLE = "ACCOUNTADMIN"
SNOWFLAKE_WAREHOUSE = "NASA_WH"
SNOWFLAKE_DATABASE = "NASA_DB"
SNOWFLAKE_SCHEMA = "PUBLIC"

VARIABLES = ["DISPH"]  # Ø§Ø±ØªÙØ§Ø¹ Ø·Ø¨Ù‚Ø© Ø§Ù„Ø®Ù„Ø·

# ==========================
# Helper Function
# ==========================
def get_snowflake_connection():
    """Create Snowflake connection"""
    return snowflake.connector.connect(
        account=SNOWFLAKE_ACCOUNT,
        user=SNOWFLAKE_USER,
        password=SNOWFLAKE_PASSWORD,
        authenticator=SNOWFLAKE_AUTHENTICATOR,
        warehouse=SNOWFLAKE_WAREHOUSE,
        database=SNOWFLAKE_DATABASE,
        schema=SNOWFLAKE_SCHEMA,
        role=SNOWFLAKE_ROLE
    )

def get_season(month):
    """ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ÙØµÙ„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø´Ù‡Ø±"""
    if month in [12, 1, 2]:
        return "Winter"
    elif month in [3, 4, 5]:
        return "Spring"
    elif month in [6, 7, 8]:
        return "Summer"
    else:
        return "Autumn"

def get_mixing_height_category(height):
    """ØªØµÙ†ÙŠÙ Ø§Ø±ØªÙØ§Ø¹ Ø·Ø¨Ù‚Ø© Ø§Ù„Ø®Ù„Ø·"""
    if height < 500:
        return "Very Low"
    elif height < 1000:
        return "Low"
    elif height < 1500:
        return "Moderate"
    elif height < 2000:
        return "High"
    else:
        return "Very High"

# ==========================
# DAGSTER OPS - DAILY AVERAGE FOR DISPH
# ==========================

@op(out=DynamicOut())
def search_nasa_files_disph_2022(context):
    """
    Ø¨Ø­Ø« Ø¹Ù† Ù…Ù„ÙØ§Øª NASA Ù„Ø³Ù†Ø© 2022 ÙƒØ§Ù…Ù„Ø© Ù„ÙƒÙ„ Ù…ØµØ±
    """
    context.log.info("ğŸ” Logging into NASA Earthdata...")
    auth = earthaccess.login(strategy="environment")
    
    context.log.info("ğŸ” Searching for NASA files for 2022...")
    
    results = earthaccess.search_data(
        short_name="M2T1NXSLV",
        version="5.12.4",
        temporal=("2022-01-01", "2022-12-31"),
        bounding_box=(25.0, 22.0, 37.0, 32.0)
    )
    
    context.log.info(f"âœ… Found {len(results)} files for 2022")
    
    for idx, granule in enumerate(results):
        yield DynamicOutput(
            value=granule,
            mapping_key=f"file_{idx}"
        )

@op
def process_single_file_disph(context, granule) -> pd.DataFrame:
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„Ù ÙˆØ§Ø­Ø¯ ÙˆØ­Ø³Ø§Ø¨ Ø§Ù„Ù…ØªÙˆØ³Ø· Ø§Ù„ÙŠÙˆÙ…ÙŠ Ù„Ù€ DISPH"""
    try:
        context.log.info(f"ğŸ“¥ Streaming file: {granule['meta']['native-id']}")
        file_stream = earthaccess.open([granule])[0]
        ds = xr.open_dataset(file_stream, engine="h5netcdf")
        
        all_daily_data = []
        
        for var in VARIABLES:
            if var in ds.variables:
                context.log.info(f"ğŸ“Š Processing variable: {var}")
                df = ds[[var]].to_dataframe().reset_index()
                
                if "time" not in df.columns:
                    context.log.warning("âš ï¸ No time column found")
                    continue
                
                df["time"] = pd.to_datetime(df["time"])
                df = df[
                    (df["lat"] >= 22.0) & (df["lat"] <= 32.0) &
                    (df["lon"] >= 25.0) & (df["lon"] <= 37.0)
                ]
                
                if df.empty:
                    context.log.warning("âš ï¸ No data within Egypt boundaries")
                    continue
                
                df["date"] = df["time"].dt.date
                daily_avg = df.groupby(["date", "lat", "lon"])[var].mean().reset_index()
                daily_avg["variable"] = var
                all_daily_data.append(daily_avg)
        
        ds.close()
        
        if not all_daily_data:
            context.log.warning(f"âš ï¸ No DISPH variable found in file")
            return pd.DataFrame()
        
        combined = pd.concat(all_daily_data, ignore_index=True)
        context.log.info(f"âœ… Processed {len(combined)} daily DISPH records from file")
        return combined
        
    except Exception as e:
        context.log.error(f"âŒ Error processing file: {e}")
        return pd.DataFrame()

@op
def transform_daily_disph(context, df: pd.DataFrame) -> pd.DataFrame:
    """ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙŠÙˆÙ…ÙŠØ© Ù„Ù€ DISPH (Ù†Ø³Ø®Ø© Ù…ØµØ­Ø­Ø©)"""
    if df.empty:
        return df
    
    context.log.info(f"ğŸ”„ Transforming {len(df)} DISPH records...")
    
    # 1. Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ØªÙˆØ³Ø· Ø§Ù„ÙŠÙˆÙ…ÙŠ Ù„ÙƒÙ„ Ù†Ù‚Ø·Ø© Ø¬ØºØ±Ø§ÙÙŠØ©
    df["date"] = pd.to_datetime(df["time"]).dt.date
    daily_per_location = df.groupby(["date", "lat", "lon"])["DISPH"].mean().reset_index()
    
    # 2. Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¥Ù‚Ù„ÙŠÙ…ÙŠ Ø§Ù„ÙŠÙˆÙ…ÙŠ Ù…Ù† Ù…ØªÙˆØ³Ø·Ø§Øª Ø§Ù„Ù†Ù‚Ø§Ø·
    regional_daily = (
        daily_per_location
        .groupby("date")
        .agg(
            avg_mixing_height=("DISPH", "mean"),
            max_mixing_height=("DISPH", "max"),
            min_mixing_height=("DISPH", "min"),
            height_std=("DISPH", "std"),
            measurement_count=("lat", "count")  # âœ… Ø¯Ù„ÙˆÙ‚ØªÙŠ Ø¯Ù‡ Ø¹Ø¯Ø¯ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø¬ØºØ±Ø§ÙÙŠØ©!
        )
        .reset_index()
    )
    
    # 3. Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ® ÙˆØ§Ù„ÙØµÙ„
    regional_daily["year"] = pd.to_datetime(regional_daily["date"]).dt.year
    regional_daily["month"] = pd.to_datetime(regional_daily["date"]).dt.month
    regional_daily["day"] = pd.to_datetime(regional_daily["date"]).dt.day
    regional_daily["day_of_year"] = pd.to_datetime(regional_daily["date"]).dt.dayofyear
    regional_daily["day_name"] = pd.to_datetime(regional_daily["date"]).dt.day_name()
    regional_daily["season"] = regional_daily["month"].apply(get_season)
    regional_daily["variable"] = "mixing_height"
    regional_daily["mixing_height_category"] = regional_daily["avg_mixing_height"].apply(get_mixing_height_category)
    
    # 4. ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
    result = regional_daily[[
        "date", "year", "month", "day", "day_of_year", "day_name", "season", "variable", 
        "avg_mixing_height", "max_mixing_height", "min_mixing_height", "height_std",
        "mixing_height_category", "measurement_count"
    ]]
    
    context.log.info(f"âœ… Transformed to {len(result)} daily records (avg of {regional_daily['measurement_count'].mean():.0f} grid points)")
    return result

@op
def load_daily_disph_to_snowflake(context, df: pd.DataFrame):
    """ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª DISPH Ù„Ù€ Snowflake"""
    if df.empty:
        context.log.warning("âš ï¸ Empty dataframe - skipping load")
        return "skipped"
    
    context.log.info(f"ğŸ“¤ Loading {len(df)} daily DISPH records to Snowflake...")
    
    try:
        conn = get_snowflake_connection()
        cur = conn.cursor()
        
        cur.execute("""
            CREATE TABLE IF NOT EXISTS NASA_DAILY_MIXING_HEIGHT (
                date DATE, year INT, month INT, day INT, day_of_year INT,
                day_name STRING, season STRING, variable STRING,
                avg_mixing_height FLOAT, max_mixing_height FLOAT,
                min_mixing_height FLOAT, height_std FLOAT,
                mixing_height_category STRING, measurement_count INT,
                loaded_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP()
            )
        """)
        
        insert_query = """
            INSERT INTO NASA_DAILY_MIXING_HEIGHT 
            (date, year, month, day, day_of_year, day_name, season, variable, 
             avg_mixing_height, max_mixing_height, min_mixing_height, height_std,
             mixing_height_category, measurement_count) 
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
        """
        
        data_to_insert = [
            (
                row["date"], int(row["year"]), int(row["month"]), int(row["day"]), 
                int(row["day_of_year"]), row["day_name"], row["season"], row["variable"], 
                float(row["avg_mixing_height"]), float(row["max_mixing_height"]),
                float(row["min_mixing_height"]), float(row["height_std"]),
                row["mixing_height_category"], int(row["measurement_count"])
            )
            for _, row in df.iterrows()
        ]
        
        cur.executemany(insert_query, data_to_insert)
        conn.commit()
        cur.close()
        conn.close()
        
        context.log.info(f"âœ… Successfully loaded {len(df)} daily DISPH records for Egypt")
        return "success"
        
    except Exception as e:
        context.log.error(f"âŒ Error loading to Snowflake: {e}")
        raise

@job
def nasa_daily_mixing_height_2022_pipeline():
    """Pipeline Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ø±ØªÙØ§Ø¹ Ø·Ø¨Ù‚Ø© Ø§Ù„Ø®Ù„Ø·"""
    files = search_nasa_files_disph_2022()
    processed = files.map(process_single_file_disph)
    transformed = processed.map(transform_daily_disph)
    transformed.map(load_daily_disph_to_snowflake)
